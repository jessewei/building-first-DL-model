{
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Buiding Your First Machine Learning Model\n\nIn this Tutorial you will learn how to build a Convolutional Neural Network (CNN) to identify handwriting. It is an introductory tutorial that will teach you how to create the different layers in a CNN using the tensorflow library. "
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## What is a Neural Network\n\nA neural network (NN) is a machine learning model that is used to classify and predict a certain variable using a set of features in the data. Typically, it consists of an input layer that takes in the features, a number of hidden layers (more layer -> deep NN), and an oputput layer that returns the prediction. The layers in the NN are are composed of Neurons (aka Perceptrons), which are essentially a mathematical function in the from of `y = Wx + b` where W is the weight and b is the biase. Also, typically the output of a perceptron is passed to an [activation function which normalizes the result](https://en.wikipedia.org/wiki/Activation_function). \n\nA CNN is basically a NN with one or more of its hidden layers, typically first, being a [Convolution](https://en.wikipedia.org/wiki/Convolution). This allows the NN to extract features from input such as images.\n\n![NN](https://i.imgur.com/xPMkf4i.png)\n\n```\nBaced on 'A deep MNIST classifier using convolutional layers'.\nSee extensive documentation at\nhttps://www.tensorflow.org/get_started/mnist/pros\n```\n"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Imports\n\nThis tutorial uses [Tensorflow](https://www.tensorflow.org/), which is an open source library released by Google. \n\nIn order to be able to build, test, and run a NN in Tensorflow, the following imports have to be used.\nThis also imports the MNIST data set (each point in the data set is a handwritten reprentation of the digits 0-9 in 784 pixels)"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "\"\"\"A deep MNIST classifier using convolutional layers.\nSee extensive documentation at\nhttps://www.tensorflow.org/get_started/mnist/pros\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tempfile\nimport argparse\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport tensorflow as tf\n", 
            "execution_count": 2
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Building Blocks\n\nIn order to build a CNN, we need to define the basic building blocks: A convolution function, a max pool function, a weight, and a biase. These 4 functions will be later combined form the perceptrons and different layers in the CNN."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "# Convolution\ndef conv2d(x, W):\n  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n# Max Pool \ndef max_pool_2x2(x):\n  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')\n\n# Weight \ndef weight_variable(shape):\n  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\n# Biase\ndef bias_variable(shape):\n  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)", 
            "execution_count": 3
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## The Neural Network\n\nThis section of the code focuses on defining the CNN and the structure of the CNN. First the input is reshaped into a 28x28x1 tensor (array). \n\nIn the first layer: the input is convoluted with by a weight and then the biase is added. The result is then normalised using the relu function. \n\nIn the second layer: max pooling is applied to reduce the dimentionality after applying the convolution.\n\nThese two layers are repeated twice.\n\nThen, then result of the second pooling layer is passed to a connected layer, then is passed through a dropout filter to reduce overfitting, and eventually the recuded-complexity \nmodel is passed to an output connected layer.\n\nThe output layer returns one of 10 classes pertaining to the digits 0-9."
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "def deepnn(x):\n  \"\"\"deepnn builds the graph for a deep net for classifying digits.\n  Args:\n    x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n    number of pixels in a standard MNIST image.\n  Returns:\n    A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n    equal to the logits of classifying the digit into one of 10 classes (the\n    digits 0-9). keep_prob is a scalar placeholder for the probability of\n    dropout.\n  \"\"\"\n  # Reshape to use within a convolutional neural net.\n  # Last dimension is for \"features\" - there is only one here, since images are\n  # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n  with tf.name_scope('reshape'):\n    x_image = tf.reshape(x, [-1, 28, 28, 1])\n\n  # First convolutional layer - maps one grayscale image to 32 feature maps.\n  with tf.name_scope('conv1'):\n    W_conv1 = weight_variable([5, 5, 1, 32])\n    b_conv1 = bias_variable([32])\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n\n  # Pooling layer - downsamples by 2X.\n  with tf.name_scope('pool1'):\n    h_pool1 = max_pool_2x2(h_conv1)\n\n  # Second convolutional layer -- maps 32 feature maps to 64.\n  with tf.name_scope('conv2'):\n    W_conv2 = weight_variable([5, 5, 32, 64])\n    b_conv2 = bias_variable([64])\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n\n  # Second pooling layer.\n  with tf.name_scope('pool2'):\n    h_pool2 = max_pool_2x2(h_conv2)\n\n  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n  with tf.name_scope('fc1'):\n    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n    b_fc1 = bias_variable([1024])\n\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n  # Dropout - controls the complexity of the model, prevents co-adaptation of\n  # features.\n  with tf.name_scope('dropout'):\n    keep_prob = tf.placeholder(tf.float32)\n    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n  # Map the 1024 features to 10 classes, one for each digit\n  with tf.name_scope('fc2'):\n    W_fc2 = weight_variable([1024, 10])\n    b_fc2 = bias_variable([10])\n\n    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n  return y_conv, keep_prob\n", 
            "execution_count": 4
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Building the CNN\n\nHaving defied the CNN, we then build it.\n\nFirst: the data set is imported into the environment and stored in the variable `mnist`.\n\nSecond: the input and outpu are defined as `x` and `_y` and the CNN is applied to `x`.\n\nThen, the cross entropy is defined as the error function to be reduced and the training method is defined as well.\n\nFinally, the accuracy is calculated and the Tensorflow graph is defined."
        }, 
        {
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "text": "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\nSaving graph to: /gpfs/fs01/user/s3be-1ef17c273e0309-b0890f841249/notebook/tmp/tmpytJ6tG\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "source": "# Import data\nmnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n\n# Create the model\nx = tf.placeholder(tf.float32, [None, 784])\n\n# Define loss and optimizer\ny_ = tf.placeholder(tf.float32, [None, 10])\n\n# Build the graph for the deep net\ny_conv, keep_prob = deepnn(x)\n\nwith tf.name_scope('loss'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n                                                            logits=y_conv)\ncross_entropy = tf.reduce_mean(cross_entropy)\n\nwith tf.name_scope('adam_optimizer'):\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\nwith tf.name_scope('accuracy'):\n    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n    correct_prediction = tf.cast(correct_prediction, tf.float32)\naccuracy = tf.reduce_mean(correct_prediction)\n\ngraph_location = tempfile.mkdtemp()\nprint('Saving graph to: %s' % graph_location)\ntrain_writer = tf.summary.FileWriter(graph_location)\ntrain_writer.add_graph(tf.get_default_graph())", 
            "execution_count": 5
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Training the CNN\n\nThe last step is doing the actual training of the CNN. "
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "text": "step 0, training accuracy 0.04\nstep 100, training accuracy 0.86\nstep 200, training accuracy 0.92\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }, 
                {
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-6-10b2b972855b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             x: batch[0], y_: batch[1], keep_prob: 1.0})\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step %d, training accuracy %g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     print('test accuracy %g' % accuracy.eval(feed_dict={\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v70/notebook/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1704\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m     \"\"\"\n\u001b[0;32m-> 1706\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v70/notebook/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3961\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3962\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3963\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v70/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v70/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v70/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v70/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v70/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ], 
                    "output_type": "error", 
                    "evalue": "", 
                    "ename": "KeyboardInterrupt"
                }
            ], 
            "source": "with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(20000):\n      batch = mnist.train.next_batch(50)\n      if i % 100 == 0:\n        train_accuracy = accuracy.eval(feed_dict={\n            x: batch[0], y_: batch[1], keep_prob: 1.0})\n        print('step %d, training accuracy %g' % (i, train_accuracy))\n      train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\n    print('test accuracy %g' % accuracy.eval(feed_dict={\n        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))", 
            "execution_count": 6
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Conclusion\n"
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "version": "2.7.11", 
            "file_extension": ".py", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "nbconvert_exporter": "python", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat_minor": 1
}